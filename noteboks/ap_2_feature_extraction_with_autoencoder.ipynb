{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ap_2_feature_extraction_with_autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "904BtEwdUUts"
      },
      "source": [
        "# RecVis Assigment 3 \n",
        "\n",
        "**Author:** Arthur Pignet\n",
        "arthur.pignet@mines-paristech.fr\n",
        "\n",
        "This notebook is the second of the two notebook I did for this assigment.\n",
        "\n",
        "It covers an approach with feature extraction via an autoencoder trained on unlabelled data. The unlabelled data are extracted from the 2019 iNaturalist dataset.\n",
        "\n",
        "The first notebook covered the native CNN training, finetuning of a ResNet pretrained on ImageNet and a features extraction with scattering wavelet network followed by a CNN.\n",
        "\n",
        "The notebook has been run with Google Colab, on P100 GPUs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7NZwFpCc35C"
      },
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWJyWDbBc-Io"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs-cCCl9dCTA"
      },
      "source": [
        "!git config --global user.email \"arthur.pignet@mines-paristech.fr\"\n",
        "!git config --global user.name \"arthurPignet\"\n",
        "!git clone https://github.com/arthurPignet/recvis21_a3.git\n",
        "%cd recvis21_a3\n",
        "!ls\n",
        "!pip install -r requirements.txt\n",
        "!cd .. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfC18sfWYGOP"
      },
      "source": [
        "## Download datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOmpQhOHzOqA"
      },
      "source": [
        "!wget -r https://ml-inat-competition-datasets.s3.amazonaws.com/2019/train_val2019.tar.gz \n",
        "!wget -r  https://ml-inat-competition-datasets.s3.amazonaws.com/2019/train2019.json.tar.gz\n",
        "!wget -r https://ml-inat-competition-datasets.s3.amazonaws.com/2019/val2019.json.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTf09TSoEFaB"
      },
      "source": [
        "! tar -xzf ml-inat-competition-datasets.s3.amazonaws.com/2019/train_val2019.tar.gz train_val2019/Birds # we only want the birds\n",
        "! tar -xzf ml-inat-competition-datasets.s3.amazonaws.com/2019/train2019.json.tar.gz \n",
        "! tar -xzf ml-inat-competition-datasets.s3.amazonaws.com/2019/val2019.json.tar.gz "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spe_DGLB9JLv"
      },
      "source": [
        "!rm -r ml-inat-competition-datasets.s3.amazonaws.com/ # free disk space"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZbgFC9kzceH"
      },
      "source": [
        "!wget -q https://www.di.ens.fr/willow/teaching/recvis18orig/assignment3/bird_dataset.zip\n",
        "!unzip bird_dataset.zip \n",
        "!rm bird_dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FLXl0VxYZX9"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9YDPvsYb9-c"
      },
      "source": [
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "from PIL import Image\n",
        "import os\n",
        "import os.path\n",
        "\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)\n",
        "\n",
        "from src.data import iBirdDataset, get_data_transform\n",
        "from models import VGG13AE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYTWDg1eWJU8"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4Oj-aViYeoj"
      },
      "source": [
        "## Load datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCxLQuNcY1H0"
      },
      "source": [
        "### Data related parameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpJFSkfIY4MZ"
      },
      "source": [
        "input_size = 224\n",
        "batch_size = 48\n",
        "labelled_data_dir = \"./bird_dataset/\"\n",
        "unlabelled_data_dir = \"./\"\n",
        "data_transforms = get_data_transform(input_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdGA48oPaTb5"
      },
      "source": [
        "### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CAkejOUdl5e"
      },
      "source": [
        "train_data = BirdDataset(root = '.',\n",
        "                        annFile = 'train2019.json',\n",
        "                        transform=data_transforms['train'])\n",
        "\n",
        "val_data = BirdDataset(root = '.',\n",
        "                        annFile = 'val2019.json',\n",
        "                        transform=data_transforms['val'])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data,\n",
        "    batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "val_loader = torch.utils.data.DataLoader(val_data,\n",
        "    batch_size=12, shuffle=False, num_workers=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjF6TMpwbbEy"
      },
      "source": [
        "print('Number of samples: ', len(train_data))\n",
        "img, target = train_data[np.random.randint(len(train_data))] # load random sample\n",
        "\n",
        "print(\"Image Size: \", img.size())\n",
        "plt.imshow(img.numpy().transpose([1, 2, 0]) )\n",
        "print(target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9eoq3IUe8gM"
      },
      "source": [
        "labelled_train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.ImageFolder(labelled_data_dir + '/train_images',\n",
        "                         transform=data_transforms['train']),\n",
        "    batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "labelled_val_loader = torch.utils.data.DataLoader(\n",
        "    datasets.ImageFolder(labelled_data_dir + '/val_images',\n",
        "                         transform=data_transforms['val']),\n",
        "    batch_size=batch_size, shuffle=False, num_workers=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee4IaDulX9bY"
      },
      "source": [
        "## Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V4bI4qZZ6xA"
      },
      "source": [
        "model = VGG13AE(latent_space_dim=512)\n",
        "model.mode_autoencoder = True\n",
        "model.cuda()\n",
        "summary(model, (3,224,224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeiXxiF6ffZ-"
      },
      "source": [
        "## Training\n",
        "\n",
        "I started by 8 epochs of autoencoder, which is realy long even on P100 GPU (~2hours), the model is big, and there is lots of data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCeslvOMfhtT"
      },
      "source": [
        "# parameters\n",
        "num_epochs_clas = 15\n",
        "num_epochs_ae = 8\n",
        "\n",
        "lr = 0.01\n",
        "momentum = 0.8\n",
        "\n",
        "log_interval = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdJxZKkBai-o"
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "def train_classifier(epoch):\n",
        "    model.train()\n",
        "    model.mode_autoencoder = False\n",
        "    for batch_idx, (data, target) in enumerate(labelled_train_loader):\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(labelled_train_loader.dataset),\n",
        "                100. * batch_idx / len(labelled_train_loader), loss.data.item()))\n",
        "            \n",
        "def train_autoencoder(epoch):\n",
        "    model.train()\n",
        "    model.mode_autoencoder = True\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        if use_cuda:\n",
        "            data= data.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        criterion = nn.MSELoss()\n",
        "        loss = criterion(output, data)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
        "\n",
        "def validation_autoencoder():\n",
        "    model.eval()\n",
        "    validation_loss = 0\n",
        "    model.mode_autoencoder = True\n",
        "    for data, target in val_loader:\n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "        output = model(data)\n",
        "        # sum up batch loss\n",
        "        criterion = nn.MSELoss()\n",
        "        validation_loss += criterion(output, data).data.item()\n",
        "\n",
        "    print('\\nValidation set: Average loss: {:.4f}'.format(\n",
        "        validation_loss))\n",
        "    \n",
        "    return validation_loss\n",
        "\n",
        "def validation_classifier():\n",
        "    model.eval()\n",
        "    model.mode_autoencoder = False\n",
        "    validation_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in labelled_val_loader:\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        output = model(data)\n",
        "        # sum up batch loss\n",
        "        criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "        validation_loss += criterion(output, target).data.item()\n",
        "        # get the index of the max log-probability\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    validation_loss /= len(val_loader.dataset)\n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "        validation_loss, correct, len(labelled_val_loader.dataset),\n",
        "        100. * correct / len(labelled_val_loader.dataset)))\n",
        "    \n",
        "    return validation_loss, 100. * correct / len(labelled_val_loader.dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYHDo5vXfu9f"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    print('Using GPU')\n",
        "    model.cuda()\n",
        "else:\n",
        "    print('Using CPU')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1P63_clfys3"
      },
      "source": [
        "for epoch in range(1, num_epochs_ae + 1):\n",
        "  train_autoencoder(epoch)\n",
        "  val_loss_ae = validation_autoencoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws8UbDZNux8R"
      },
      "source": [
        "best_epoch = 0\n",
        "best_loss = 100000\n",
        "patience=0\n",
        "for epoch in range(1, num_epochs_clas + 1):\n",
        "  \n",
        "    train_classifier(epoch)\n",
        "    val_loss, val_acc = validation_classifier()\n",
        "    val_loss_per_epoch_ae.append(val_loss)\n",
        "    if val_loss < best_loss:\n",
        "      patience = 0\n",
        "      best_epoch = epoch\n",
        "      best_loss = val_loss\n",
        "      best_state = model.state_dict()\n",
        "    else:\n",
        "      patience += 1\n",
        "\n",
        "    \n",
        "    if patience > 4:\n",
        "      break\n",
        "      #model_file = experiment + '/model_' + str(epoch) + '.pth'\n",
        "    #torch.save(model.state_dict(), model_file)\n",
        "   # print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwRCBCNpxj2E"
      },
      "source": [
        "##kaggle submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMTRs9sGxlG7"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "import PIL.Image as Image\n",
        "from src.utils import pil_loader\n",
        "data_dir = 'bird_dataset'\n",
        "test_dir = data_dir + '/test_images/mistery_category'\n",
        "experiment = 'recvis21_a3/experiment_ae_features'\n",
        "\n",
        "output_file = open(f'{experiment}/result_ae_features.csv', \"w\")\n",
        "output_file.write(\"Id,Category\\n\")\n",
        "for f in tqdm(os.listdir(test_dir)):\n",
        "    if 'jpg' in f:\n",
        "        data = data_transforms['val'](pil_loader(test_dir + '/' + f))\n",
        "        data = data.view(1, data.size(0), data.size(1), data.size(2))\n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "        #sc = scattering(data)\n",
        "        output = model(data)\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        output_file.write(\"%s,%d\\n\" % (f[:-4], pred))\n",
        "\n",
        "output_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NAOkEYbXyQC"
      },
      "source": [
        "%cd recvis21_a3/\n",
        "!git add ae_features/result_without_ae_features.csv\n",
        "!git commit -m 'add result ae features'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcNd57RL4o6V"
      },
      "source": [
        "!git push"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3DSefrBW7UG"
      },
      "source": [
        "### Comparison with the same classifier not pretrained on unlabelled data.\n",
        "\n",
        "Note that I did not have enough space on the gpu memory to have 2 models at the same time, and I often restarted the VM before lauching this part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coh6dho7XD2U"
      },
      "source": [
        "model = VGG13AE(latent_space_dim=512) \n",
        "model.mode_autoencoder = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhrt5itNbFMl"
      },
      "source": [
        "best_epoch = 0\n",
        "best_loss = 100000\n",
        "patience=0\n",
        "for epoch in range(1, num_epochs_clas + 1):\n",
        "  \n",
        "    train_classifier(epoch)\n",
        "    val_loss, val_acc = validation_classifier()\n",
        "    val_loss_per_epoch_ae.append(val_loss)\n",
        "    if val_loss < best_loss:\n",
        "      patience = 0\n",
        "      best_epoch = epoch\n",
        "      best_loss = val_loss\n",
        "      best_state = model.state_dict()\n",
        "    else:\n",
        "      patience += 1\n",
        "\n",
        "    \n",
        "    if patience > 4:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRcKSdsAbSPs"
      },
      "source": [
        "### Kaggle submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM5QM8Y5a7X5"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "import PIL.Image as Image\n",
        "from src.utils import pil_loader\n",
        "data_dir = 'bird_dataset'\n",
        "test_dir = data_dir + '/test_images/mistery_category'\n",
        "experiment = 'recvis21_a3/experiment_ae_features'\n",
        "\n",
        "output_file = open(f'{experiment}/result_ae_without_features.csv', \"w\")\n",
        "output_file.write(\"Id,Category\\n\")\n",
        "for f in tqdm(os.listdir(test_dir)):\n",
        "    if 'jpg' in f:\n",
        "        data = data_transforms['val'](pil_loader(test_dir + '/' + f))\n",
        "        data = data.view(1, data.size(0), data.size(1), data.size(2))\n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "        #sc = scattering(data)\n",
        "        output = model(data)\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        output_file.write(\"%s,%d\\n\" % (f[:-4], pred))\n",
        "\n",
        "output_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an45UjexxuuV"
      },
      "source": [
        "%cd recvis21_a3/\n",
        "!git add ae_features/result_without_ae_features.csv\n",
        "!git commit -m 'add result without ae features'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYaUDgaIbgKk"
      },
      "source": [
        "!git push"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}